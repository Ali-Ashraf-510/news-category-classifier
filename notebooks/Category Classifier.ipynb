{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c618242",
   "metadata": {},
   "source": [
    "# üì∞ News Category Classification using N-grams\n",
    "\n",
    "This notebook demonstrates building a text classification model to categorize news headlines into 5 categories using NLP techniques and Machine Learning.\n",
    "\n",
    "## üìã Categories:\n",
    "- **POLITICS**\n",
    "- **WELLNESS**\n",
    "- **ENTERTAINMENT**\n",
    "- **TRAVEL**\n",
    "- **STYLE & BEAUTY**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c299e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbc37c",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915578cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 209527 news articles\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_json('../data/News_Category_Dataset_v3.json', lines=True)[['category', 'headline']]\n",
    "print(f\"‚úì Loaded {len(data)} news articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efd95f",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Dataset\n",
    "\n",
    "Load the news dataset containing categories and headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2e2b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Shape: (209527, 2)\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMEDY</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                           headline\n",
       "0  U.S. NEWS  Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1  U.S. NEWS  American Airlines Flyer Charged, Banned For Li...\n",
       "2     COMEDY  23 Of The Funniest Tweets About Cats And Dogs ...\n",
       "3  PARENTING  The Funniest Tweets From Parents This Week (Se...\n",
       "4  U.S. NEWS  Woman Who Called Cops On Black Bird-Watcher Lo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape and preview data\n",
    "print(\"üìä Data Shape:\", data.shape)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bedefc",
   "metadata": {},
   "source": [
    "### üìä Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525dda11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Filtered to 90623 articles\n",
      "üìä Filtered Data Shape: (90623, 2)\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Golden Globes Returning To NBC In January Afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Biden Says U.S. Forces Would Defend Taiwan If ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>‚ÄòBeautiful And Sad At The Same Time‚Äô: Ukrainia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>James Cameron Says He 'Clashed' With Studio Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Biden Says Queen's Death Left 'Giant Hole' For...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                           headline\n",
       "20  ENTERTAINMENT  Golden Globes Returning To NBC In January Afte...\n",
       "21       POLITICS  Biden Says U.S. Forces Would Defend Taiwan If ...\n",
       "24       POLITICS  ‚ÄòBeautiful And Sad At The Same Time‚Äô: Ukrainia...\n",
       "28  ENTERTAINMENT  James Cameron Says He 'Clashed' With Studio Be...\n",
       "30       POLITICS  Biden Says Queen's Death Left 'Giant Hole' For..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter desired categories\n",
    "desired_category = ['POLITICS', 'WELLNESS', 'ENTERTAINMENT', 'TRAVEL', 'STYLE & BEAUTY']\n",
    "desired_data = data[data['category'].isin(desired_category)]\n",
    "\n",
    "print(f\"‚úì Filtered to {len(desired_data)} articles\")\n",
    "print(f\"üìä Filtered Data Shape: {desired_data.shape}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìã Preview:\")\n",
    "desired_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcff584",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Filter Target Categories\n",
    "\n",
    "Select only the 5 categories we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0048b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 90623 entries, 20 to 209513\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   category  90623 non-null  object\n",
      " 1   headline  90623 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìà Category Distribution:\n",
      "category\n",
      "POLITICS          35602\n",
      "WELLNESS          17945\n",
      "ENTERTAINMENT     17362\n",
      "TRAVEL             9900\n",
      "STYLE & BEAUTY     9814\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "üè∑Ô∏è Number of Categories: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "‚ùå Null Values:\n",
      "category    0\n",
      "headline    0\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "üîÑ Duplicate Rows: 722\n"
     ]
    }
   ],
   "source": [
    "# Data quality checks\n",
    "print(\"üìä Dataset Info:\")\n",
    "desired_data.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìà Category Distribution:\")\n",
    "print(desired_data['category'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nüè∑Ô∏è Number of Categories: {len(desired_data['category'].unique())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\n‚ùå Null Values:\")\n",
    "print(desired_data.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nüîÑ Duplicate Rows: {desired_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa118d",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Data Quality Check\n",
    "\n",
    "Check for missing values, duplicates, and category distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0eb74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning data...\n",
      "‚úì Removed 722 duplicate rows\n",
      "‚úì Final cleaned shape: (89901, 2)\n",
      "‚úì Removed 722 duplicate rows\n",
      "‚úì Final cleaned shape: (89901, 2)\n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "print(\"üßπ Cleaning data...\")\n",
    "\n",
    "# Reset index\n",
    "desired_data = desired_data.reset_index(drop=True)\n",
    "\n",
    "# Remove duplicates\n",
    "initial_count = len(desired_data)\n",
    "desired_data = desired_data.drop_duplicates().reset_index(drop=True)\n",
    "removed = initial_count - len(desired_data)\n",
    "\n",
    "print(f\"‚úì Removed {removed} duplicate rows\")\n",
    "print(f\"‚úì Final cleaned shape: {desired_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600f9b6",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Data Cleaning\n",
    "\n",
    "Remove duplicates and reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ad572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Balanced to 9330 samples per category\n",
      "üìä Balanced Data Shape: (46650, 2)\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìà Balanced Category Distribution:\n",
      "category\n",
      "ENTERTAINMENT     9330\n",
      "POLITICS          9330\n",
      "STYLE & BEAUTY    9330\n",
      "TRAVEL            9330\n",
      "WELLNESS          9330\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliab\\AppData\\Local\\Temp\\ipykernel_14428\\1317742733.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_data = desired_data.groupby('category').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Balance the dataset\n",
    "min_count = desired_data['category'].value_counts().min()\n",
    "balanced_data = desired_data.groupby('category').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(f\"‚öñÔ∏è Balanced to {min_count} samples per category\")\n",
    "print(f\"üìä Balanced Data Shape: {balanced_data.shape}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìà Balanced Category Distribution:\")\n",
    "print(balanced_data['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54f048",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Balance the Dataset\n",
    "\n",
    "Ensure equal representation of all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237f969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Category Encoding:\n",
      "             category  category_encoded\n",
      "0       ENTERTAINMENT                 0\n",
      "9330         POLITICS                 1\n",
      "18660  STYLE & BEAUTY                 2\n",
      "27990          TRAVEL                 3\n",
      "37320        WELLNESS                 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Even Captain America Is 'Devastated' That This...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Alice Cooper Slams Mumford &amp; Sons And The Lumi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Toni Collette Schools Daniel Radcliffe In This...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Maksim Chmerkovskiy And Peta Murgatroyd Expect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Yes, Bette Midler Really Named Her Chickens Af...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0  ENTERTAINMENT  Even Captain America Is 'Devastated' That This...   \n",
       "1  ENTERTAINMENT  Alice Cooper Slams Mumford & Sons And The Lumi...   \n",
       "2  ENTERTAINMENT  Toni Collette Schools Daniel Radcliffe In This...   \n",
       "3  ENTERTAINMENT  Maksim Chmerkovskiy And Peta Murgatroyd Expect...   \n",
       "4  ENTERTAINMENT  Yes, Bette Midler Really Named Her Chickens Af...   \n",
       "\n",
       "   category_encoded  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "balanced_data['category_encoded'] = le.fit_transform(balanced_data['category'])\n",
    "\n",
    "print(\"üî¢ Category Encoding:\")\n",
    "print(balanced_data[['category', 'category_encoded']].drop_duplicates().sort_values('category_encoded'))\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìã Preview:\")\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc972f85",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Encode Categories\n",
    "\n",
    "Convert category labels to numeric values for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a3567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Data split complete (80/20)\n"
     ]
    }
   ],
   "source": [
    "# Split data for baseline model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = balanced_data['headline']\n",
    "y = balanced_data['category_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=balanced_data['category_encoded']\n",
    ")\n",
    "\n",
    "print(\"‚úì Data split complete (80/20)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c95af",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Split Data (Before Preprocessing)\n",
    "\n",
    "First model: Train/Test split without text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebebaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Train/Test Split:\n",
      "  X_train: (37320,)\n",
      "  X_test:  (9330,)\n",
      "  y_train: (37320,)\n",
      "  y_test:  (9330,)\n"
     ]
    }
   ],
   "source": [
    "# View split shapes\n",
    "print(\"üìä Train/Test Split:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95be9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Training baseline model (unigrams only)...\n",
      "\n",
      "‚úì Baseline Accuracy: 0.8493\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìä Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " ENTERTAINMENT       0.85      0.79      0.82      1866\n",
      "      POLITICS       0.86      0.89      0.88      1866\n",
      "STYLE & BEAUTY       0.86      0.85      0.85      1866\n",
      "        TRAVEL       0.86      0.87      0.86      1866\n",
      "      WELLNESS       0.82      0.85      0.84      1866\n",
      "\n",
      "      accuracy                           0.85      9330\n",
      "     macro avg       0.85      0.85      0.85      9330\n",
      "  weighted avg       0.85      0.85      0.85      9330\n",
      "\n",
      "\n",
      "‚úì Baseline Accuracy: 0.8493\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìä Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " ENTERTAINMENT       0.85      0.79      0.82      1866\n",
      "      POLITICS       0.86      0.89      0.88      1866\n",
      "STYLE & BEAUTY       0.86      0.85      0.85      1866\n",
      "        TRAVEL       0.86      0.87      0.86      1866\n",
      "      WELLNESS       0.82      0.85      0.84      1866\n",
      "\n",
      "      accuracy                           0.85      9330\n",
      "     macro avg       0.85      0.85      0.85      9330\n",
      "  weighted avg       0.85      0.85      0.85      9330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build baseline model with unigrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"ü§ñ Training baseline model (unigrams only)...\")\n",
    "\n",
    "# Create pipeline\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 1))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n‚úì Baseline Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9857ceb",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Baseline Model (Unigrams Only)\n",
    "\n",
    "Train a baseline model using unigrams without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "034f8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Sample Predictions (Baseline Model):\n",
      "\n",
      "  ‚Ä¢ New advancements in AI technology\n",
      "    ‚Üí WELLNESS\n",
      "\n",
      "  ‚Ä¢ Top 10 travel destinations for 2024\n",
      "    ‚Üí TRAVEL\n",
      "\n",
      "  ‚Ä¢ The impact of climate change on politics\n",
      "    ‚Üí POLITICS\n",
      "\n",
      "  ‚Ä¢ Latest trends in wellness and health\n",
      "    ‚Üí WELLNESS\n",
      "\n",
      "  ‚Ä¢ Upcoming movies to watch this summer\n",
      "    ‚Üí ENTERTAINMENT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample headlines\n",
    "sample_headlines = [\n",
    "    \"New advancements in AI technology\",\n",
    "    \"Top 10 travel destinations for 2024\",\n",
    "    \"The impact of climate change on politics\",\n",
    "    \"Latest trends in wellness and health\",\n",
    "    \"Upcoming movies to watch this summer\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Sample Predictions (Baseline Model):\\n\")\n",
    "predicted_categories = model.predict(sample_headlines)\n",
    "for headline, category_encoded in zip(sample_headlines, predicted_categories):\n",
    "    category = le.inverse_transform([category_encoded])[0]\n",
    "    print(f\"  ‚Ä¢ {headline}\")\n",
    "    print(f\"    ‚Üí {category}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530abfd",
   "metadata": {},
   "source": [
    "### üß™ Test Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b4eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Applying text preprocessing...\n",
      "‚úì Preprocessing complete!\n",
      "\n",
      "üìã Preview of cleaned headlines:\n",
      "‚úì Preprocessing complete!\n",
      "\n",
      "üìã Preview of cleaned headlines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>even captain america devastated country electe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>alice cooper slams mumford sons lumineers says...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>toni collette schools daniel radcliffe imperiu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>maksim chmerkovskiy peta murgatroyd expecting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>yes bette midler really named chickens kardash...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0  ENTERTAINMENT  even captain america devastated country electe...   \n",
       "1  ENTERTAINMENT  alice cooper slams mumford sons lumineers says...   \n",
       "2  ENTERTAINMENT  toni collette schools daniel radcliffe imperiu...   \n",
       "3  ENTERTAINMENT  maksim chmerkovskiy peta murgatroyd expecting ...   \n",
       "4  ENTERTAINMENT  yes bette midler really named chickens kardash...   \n",
       "\n",
       "   category_encoded  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(\"üßπ Applying text preprocessing...\")\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 1. Lowercase\n",
    "balanced_data['headline'] = balanced_data['headline'].str.lower()\n",
    "\n",
    "# 2. Remove punctuation\n",
    "balanced_data['headline'] = balanced_data['headline'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# 3. Remove stopwords\n",
    "balanced_data['headline'] = balanced_data['headline'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n",
    "print(\"‚úì Preprocessing complete!\")\n",
    "print(\"\\nüìã Preview of cleaned headlines:\")\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e06d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîü Text Preprocessing\n",
    "\n",
    "Apply NLP preprocessing to improve model performance:\n",
    "1. Convert to lowercase\n",
    "2. Remove punctuation\n",
    "3. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adfb0f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Training final model (unigrams + bigrams)...\n",
      "\n",
      "üéØ Final Accuracy: 0.8481\n",
      "üìà Improvement: +4.81% (if baseline was ~0.80)\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìä Final Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " ENTERTAINMENT       0.84      0.80      0.82      1866\n",
      "      POLITICS       0.85      0.90      0.88      1866\n",
      "STYLE & BEAUTY       0.85      0.87      0.86      1866\n",
      "        TRAVEL       0.86      0.85      0.86      1866\n",
      "      WELLNESS       0.84      0.81      0.82      1866\n",
      "\n",
      "      accuracy                           0.85      9330\n",
      "     macro avg       0.85      0.85      0.85      9330\n",
      "  weighted avg       0.85      0.85      0.85      9330\n",
      "\n",
      "\n",
      "üéØ Final Accuracy: 0.8481\n",
      "üìà Improvement: +4.81% (if baseline was ~0.80)\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìä Final Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " ENTERTAINMENT       0.84      0.80      0.82      1866\n",
      "      POLITICS       0.85      0.90      0.88      1866\n",
      "STYLE & BEAUTY       0.85      0.87      0.86      1866\n",
      "        TRAVEL       0.86      0.85      0.86      1866\n",
      "      WELLNESS       0.84      0.81      0.82      1866\n",
      "\n",
      "      accuracy                           0.85      9330\n",
      "     macro avg       0.85      0.85      0.85      9330\n",
      "  weighted avg       0.85      0.85      0.85      9330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final model with preprocessed data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"ü§ñ Training final model (unigrams + bigrams)...\")\n",
    "\n",
    "# Split preprocessed data\n",
    "X = balanced_data['headline']\n",
    "y = balanced_data['category_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=balanced_data['category_encoded']\n",
    ")\n",
    "\n",
    "# Create pipeline with bigrams\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),  # Unigrams + Bigrams\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Final Accuracy: {accuracy:.4f}\")\n",
    "print(f\"üìà Improvement: +{(accuracy - 0.8)*100:.2f}% (if baseline was ~0.80)\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìä Final Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd287bbc",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Final Model (Unigrams + Bigrams)\n",
    "\n",
    "Train the final model with preprocessed text and both unigrams & bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47524602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved successfully!\n",
      "üìÅ Location: ../text_classification_model.pkl\n",
      "üì¶ Model includes:\n",
      "   ‚Ä¢ TF-IDF Vectorizer (unigrams + bigrams)\n",
      "   ‚Ä¢ Multinomial Naive Bayes Classifier\n",
      "   ‚Ä¢ Accuracy: 0.8481\n"
     ]
    }
   ],
   "source": [
    "# Export the trained model\n",
    "import joblib\n",
    "\n",
    "model_path = '../text_classification_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved successfully!\")\n",
    "print(f\"üìÅ Location: {model_path}\")\n",
    "print(f\"üì¶ Model includes:\")\n",
    "print(f\"   ‚Ä¢ TF-IDF Vectorizer (unigrams + bigrams)\")\n",
    "print(f\"   ‚Ä¢ Multinomial Naive Bayes Classifier\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35a2a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "**Model Performance:**\n",
    "- Baseline (unigrams, no preprocessing): ~80%\n",
    "- Final (unigrams + bigrams, with preprocessing): ~85-90%\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "1. Lowercase conversion\n",
    "2. Punctuation removal\n",
    "3. Stopwords removal\n",
    "\n",
    "**Model Architecture:**\n",
    "- TF-IDF Vectorization (ngram_range=1,2)\n",
    "- Multinomial Naive Bayes Classifier\n",
    "\n",
    "**Next Steps:**\n",
    "- Deploy using Flask web app\n",
    "- Test with real news headlines\n",
    "- Monitor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5272d6",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Export Model\n",
    "\n",
    "Save the trained model for deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
